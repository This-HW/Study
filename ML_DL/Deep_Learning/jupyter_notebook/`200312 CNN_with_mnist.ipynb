{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\didix\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\didix\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\didix\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\didix\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\didix\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\didix\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# data import\n",
    "mnist = input_data.read_data_sets(\"/tmp/tensorflow/mnist/input_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.train.images.shape :  (55000, 784)\n",
      "mnist.test.images.shape :  (10000, 784)\n",
      "mnist.validation.images.shape :  (5000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Under stand data\n",
    "# print(\"mnist.train : \",mnist.train)\n",
    "# print(\"mnist.test : \",mnist.test)\n",
    "# print(\"mnist.validation : \",mnist.validation)\n",
    "# print(\"mnist.train.images : \",mnist.train.images)\n",
    "# print(\"mnist.test.images : \",mnist.test.images)\n",
    "# print(\"mnist.validation.images : \",mnist.validation.images)\n",
    "print(\"mnist.train.images.shape : \",mnist.train.images.shape)\n",
    "print(\"mnist.test.images.shape : \",mnist.test.images.shape)\n",
    "print(\"mnist.validation.images.shape : \",mnist.validation.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist data is gray scale and already flatten ##\n",
    "     \n",
    "   \n",
    "- mnist.train.images : 784 size * 55000 images (55000, 784)\n",
    "- mnist.test.images : 784 size * 10000 images (10000, 784)\n",
    "- mnist.validation.images : 784 size * 5000 images (10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make nodes\n",
    "x = tf.placeholder(shape = [None, 784], dtype = tf.float32) # input place holder\n",
    "y = tf.placeholder(shape = [None,10], dtype = tf.float32) # output place holder\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10])) # weight Virable with zero / input = 784, output = 10\n",
    "b = tf.Variable(tf.zeros([10])) # bias Virable with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis\n",
    "logit = tf.matmul(x, W) + b \n",
    "H = tf.nn.softmax(logit) # Activation function : softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-a4c595d9d625>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cost fucntion & train optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logit, labels = y)) # cost function\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate = 0.05).minimize(cost) # train optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session & initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------------------\n",
      "bias is \n",
      "array([0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "       0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00], dtype=float32)\n",
      "Weight is \n",
      "array([[0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
      "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
      "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00]], dtype=float32)\n",
      "Weight shape is : (10, 10)\n",
      "-------------------------------\n",
      "\n",
      "# Learning progress \n",
      "\n",
      "epoch :     1   cost 값은    0.41521\n",
      "epoch :     2   cost 값은    0.32366\n",
      "epoch :     3   cost 값은    0.53011\n",
      "epoch :     4   cost 값은    0.44271\n",
      "epoch :     5   cost 값은    0.48854\n",
      "epoch :     6   cost 값은    0.37727\n",
      "epoch :     7   cost 값은    0.22922\n",
      "epoch :     8   cost 값은    0.41665\n",
      "epoch :     9   cost 값은    0.39721\n",
      "epoch :    10   cost 값은    0.37942\n",
      "\n",
      "\n",
      "-------------------------------\n",
      "bias is \n",
      "array([-2.55e-01, 3.10e-01, 3.22e-02, -1.91e-01, 4.08e-02, 8.90e-01,\n",
      "       -6.05e-02, 4.36e-01, -1.04e+00, -1.63e-01], dtype=float32)\n",
      "Weight is \n",
      "array([[1.18e-01, -1.95e-01, -1.80e-02, 1.72e-01, -7.96e-02, -8.94e-02,\n",
      "        -2.04e-01, 1.77e-01, 5.46e-02, 6.48e-02],\n",
      "       [1.02e-01, -1.80e-01, -3.70e-02, 6.32e-02, -7.81e-02, -2.07e-02,\n",
      "        -1.46e-01, 1.48e-01, 1.18e-01, 3.02e-02],\n",
      "       [1.80e-01, -1.51e-01, -5.07e-02, -2.84e-02, -9.21e-02, 3.90e-02,\n",
      "        -1.10e-01, 6.49e-02, 1.72e-01, -2.42e-02],\n",
      "       [2.20e-01, -1.18e-01, -8.10e-02, -6.95e-02, -1.31e-01, 2.08e-01,\n",
      "        -6.18e-02, -5.02e-02, 1.51e-01, -6.76e-02],\n",
      "       [7.59e-02, -7.61e-02, -6.68e-02, -5.18e-02, -1.04e-01, 3.76e-01,\n",
      "        -6.74e-02, -5.21e-02, 4.51e-02, -7.83e-02],\n",
      "       [-4.99e-02, -2.69e-02, -2.08e-02, -1.20e-02, -6.18e-02, 3.03e-01,\n",
      "        -6.26e-02, -2.13e-02, -1.08e-02, -3.71e-02],\n",
      "       [-1.83e-02, -5.40e-03, -1.16e-03, -1.90e-03, -1.60e-02, 7.61e-02,\n",
      "        -1.98e-02, -4.60e-03, 1.77e-03, -1.06e-02],\n",
      "       [-3.21e-04, -4.29e-05, -2.60e-04, -4.18e-05, -5.47e-04, 3.19e-03,\n",
      "        -2.72e-03, 3.23e-04, 2.08e-03, -1.66e-03],\n",
      "       [-1.51e-05, -2.27e-06, -6.43e-06, -3.46e-05, -4.02e-05, -2.94e-05,\n",
      "        -4.28e-06, 4.76e-04, -1.63e-05, -3.28e-04],\n",
      "       [2.59e-04, 4.34e-05, -2.11e-04, -1.23e-03, -3.66e-03, -1.77e-03,\n",
      "        -3.38e-04, 1.53e-02, -6.27e-04, -7.72e-03]], dtype=float32)\n",
      "Weight shape is : (10, 10)\n"
     ]
    }
   ],
   "source": [
    "# traing\n",
    "epochs=10\n",
    "batch_size = 100\n",
    "np.set_printoptions(formatter={\"float_kind\": lambda x:\"{0:.2e}\".format(x)})\n",
    "# np.set_printoptions(suppress=False)\n",
    "\n",
    "print(\"\\n\\n-------------------------------\")\n",
    "print('bias is ')\n",
    "pprint.pprint(sess.run(b))\n",
    "_tmp=sess.run(W[300:310])\n",
    "print('Weight is ')\n",
    "pprint.pprint(_tmp)\n",
    "print(f\"Weight shape is : {_tmp.shape}\")\n",
    "print(\"-------------------------------\\n\\n# Learning progress \\n\")\n",
    "\n",
    "\n",
    "for step in range(epochs):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size) # 여기에서는 550이다.\n",
    "    cost_val=0\n",
    "    \n",
    "    for i in range(num_of_iter) :\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size) \n",
    "        # mnist에서는 배치크기에 따라 데이터들을 자동으로 만들어주는 함수가 있다.\n",
    "\n",
    "        tmp_train, cost_val = sess.run([train_step, cost], feed_dict = { x : batch_xs, y : batch_ys})\n",
    "\n",
    "    print(f\"epoch : {(step+1):5}   cost 값은 {cost_val:10.5f}\")    \n",
    "#     print(\"Weight : \")\n",
    "#     _tmp=sess.run(W)\n",
    "#     pprint.pprint(_tmp)\n",
    "#     print(f\"Weight shape : {_tmp.shape}\")\n",
    "#     print(\"bias : \")\n",
    "#     pprint.pprint(sess.run(b))\n",
    "\n",
    "#     print(\"-------------------------------\\n\\n\")\n",
    "        \n",
    "print(\"\\n\\n-------------------------------\")\n",
    "print('bias is ')\n",
    "pprint.pprint(sess.run(b))\n",
    "_tmp=sess.run(W[300:310])\n",
    "print('Weight is ')\n",
    "pprint.pprint(_tmp)\n",
    "print(f\"Weight shape is : {_tmp.shape}\")\n",
    "# print('Weight is ', _tmp=sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.9202\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(H, 1), tf.argmax(y, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
    "print('accuracy ',sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "print (\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
