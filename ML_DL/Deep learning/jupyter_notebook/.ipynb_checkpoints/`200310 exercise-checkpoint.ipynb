{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "# import konlpy\n",
    "from eunjeon import Mecab\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\", encoding=\"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year_month</th>\n",
       "      <th>text</th>\n",
       "      <th>smishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id year_month                                               text  smishing\n",
       "0   0    2017-01                           XXX은행성산XXX팀장입니다.행복한주말되세요         0\n",
       "1   1    2017-01              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0\n",
       "2   2    2017-01  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0\n",
       "3   4    2017-01  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...         0\n",
       "4   5    2017-01           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 295945\n",
      "Data shape (295945, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data length: {}\".format(len(data)))\n",
    "print(\"Data shape {}\".format(data.shape))\n",
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_effect(arr):\n",
    "    words_in_brackets = ['광고']\n",
    "    ret = []\n",
    "    idx = 0\n",
    "    while idx < len(arr):\n",
    "        if arr[idx] == '(' and idx + 2 < len(arr) and arr[idx + 2] == ')':\n",
    "            if arr[idx + 1] in '일월화수목금토':\n",
    "                if len(ret) > 0 and ret[-1] == 'X':\n",
    "                    ret.pop()\n",
    "                    ret.append('X일')\n",
    "                ret.append('(요일)')\n",
    "                idx += 2\n",
    "            elif arr[idx + 1] in words_in_brackets:\n",
    "                ret.append('(' + arr[idx + 1] + ')')\n",
    "                idx += 2\n",
    "            else:\n",
    "                buff = re.sub('[0-9.X]+', 'X', arr[idx])\n",
    "                buff = re.sub('[-]+', '-', buff)\n",
    "                buff = re.sub('[X]+', 'X', buff)\n",
    "                ret.append(buff)\n",
    "        else:\n",
    "            buff = re.sub('[0-9.X]+', 'X', arr[idx])\n",
    "            buff = re.sub('[-]+', '-', buff)\n",
    "            buff = re.sub('[X]+', 'X', buff)\n",
    "            ret.append(buff)\n",
    "        idx += 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence(sentence):\n",
    "    prev_word, prev_pos = '', ''\n",
    "    nouns = []\n",
    "    words = []\n",
    "    adverbs = []\n",
    "    etc = []\n",
    "    buff = ''\n",
    "    ret = []\n",
    "    condition = False\n",
    "    idx, condidx = 0, 0\n",
    "    \n",
    "    for word, pos in mecab.pos(sentence):\n",
    "        # S인 경우 '() 각각 있는 경우 나누어서 여러개의 S로 처리'\n",
    "        if pos in ('SF') or pos[:1] in ('J'):\n",
    "            # 은/는/이/가/. 등\n",
    "            prev_word, prev_pos = '', ''\n",
    "            continue\n",
    "\n",
    "        if pos[:1] == 'N' and prev_pos[:1] == 'S':\n",
    "            # 1억, 1천만원 등\n",
    "            word = re.sub('[억천만]', '', word)\n",
    "            if len(word) == 0:\n",
    "                continue\n",
    "\n",
    "#         if pos[:1] == 'S':\n",
    "#             word = re.sub('[(:)]', '', word)\n",
    "#             word = re.sub('[0-9.X]+', 'X', word)\n",
    "\n",
    "        # 조건절 판단\n",
    "        if prev_pos[-3:] == 'ETM' and word in ['분','고객','개인','사업자','이','대상','당신','직원','VIP', '자','분도','전문직','신용자','외국인','본인','임직원','부모','회계사','귀하','투자자','분과']:\n",
    "            condition = True  \n",
    "        elif pos[:1] == 'N':\n",
    "            if word[:2] in ('경우', '필요', '라면', '다면'): # 경우, 필요 단어 등장 시 조건절로 판단\n",
    "                condition = True\n",
    "        elif pos[-2:] == 'EC':\n",
    "            # 여도, 라도, 라면, 면\n",
    "            if word[-1:] in ('면', '도') or word[-2:] in ('도록'):\n",
    "                condition = True\n",
    "\n",
    "        if pos[:1] == 'E':\n",
    "            buff += word\n",
    "        #elif pos[:1] == 'N' and prev_pos[:1] == 'N' and len(word) == 1:\n",
    "        #    buff += word\n",
    "        elif pos[:1] == 'S' and prev_pos[:1] == 'S' and word[:1] in 'X0123456789%.-': #('%', '.', '-'):\n",
    "            pos_x = re.search('[0-9X]', buff)\n",
    "            pos_x = pos_x.span()[0] if pos_x is not None else len(buff)\n",
    "            if pos_x > 0:\n",
    "                words.append(buff[:pos_x])\n",
    "                buff = buff[pos_x:]\n",
    "            \n",
    "            # 중간에 %가 있는 경우\n",
    "            if len(buff) > 0:\n",
    "                pos_pct = re.search('%', buff)\n",
    "                pos_pct = (pos_pct.span()[0] + 1) if pos_pct is not None else 0\n",
    "                if pos_pct > 0:\n",
    "                    words.append(buff[:pos_pct])\n",
    "                    buff = buff[pos_pct:]\n",
    "                \n",
    "            buff += word\n",
    "\n",
    "        elif pos[:1] in ('N', 'S') and prev_pos[:1] == 'S' and len(buff) > 0:\n",
    "            # 숫자 앞에 문자가 있는 경우\n",
    "            pos_x = re.search('[0-9X]', buff)\n",
    "            pos_x = pos_x.span()[0] if pos_x is not None else len(buff)\n",
    "            if pos_x > 0:\n",
    "                words.append(buff[:pos_x])\n",
    "                buff = buff[pos_x:]\n",
    "\n",
    "            # 중간에 %가 있는 경우\n",
    "            if len(buff) > 0:\n",
    "                pos_pct = re.search('%', buff)\n",
    "                pos_pct = (pos_pct.span()[0] + 1) if pos_pct is not None else 0\n",
    "                if pos_pct > 0:\n",
    "                    words.append(buff[:pos_pct])\n",
    "                    buff = buff[pos_pct:]\n",
    "\n",
    "            if word in ('시', '분', '초', '시간'):\n",
    "                buff = re.sub('시', '', buff)\n",
    "                buff += '시'\n",
    "            elif word in ('년', '월', '일', '개월'):\n",
    "                buff = re.sub('일', '', buff)\n",
    "                buff += '일'\n",
    "            elif word in ('원'):\n",
    "                buff = re.sub('원', '', buff)\n",
    "                buff += '원'\n",
    "                prev_word, prev_pos = word, pos\n",
    "            elif word in ('배'):\n",
    "                buff += '%'\n",
    "                prev_word, prev_pos = word, pos\n",
    "            elif word in ('kg', 'pt', '형'):\n",
    "                buff += '단위'\n",
    "                prev_word, prev_pos = word, 'N' #pos\n",
    "            elif word in ('건', '종', '대'):\n",
    "                buff += '개'\n",
    "                prev_word, prev_pos = word, pos\n",
    "            else:\n",
    "                if len(buff) > 0:\n",
    "                    words.append(buff)\n",
    "                buff = word\n",
    "        else:\n",
    "            if len(buff) > 0:\n",
    "                # 중간에 %가 있는 경우\n",
    "                if len(buff) > 0:\n",
    "                    pos_pct = re.search('%', buff)\n",
    "                    pos_pct = (pos_pct.span()[0] + 1) if pos_pct is not None else 0\n",
    "                    if pos_pct > 0:\n",
    "                        words.append(buff[:pos_pct])\n",
    "                        buff = buff[pos_pct:]\n",
    "                if True: #buff != 'X':\n",
    "                    words.append(buff)\n",
    "                    # M, N 경우만 저장해보자\n",
    "                    if prev_pos[:1] in ('N'):  # 'M', \n",
    "                        nouns.append(buff)\n",
    "                    elif prev_pos[:1] in ('M'):\n",
    "                        adverbs.append(buff)\n",
    "            buff = word\n",
    "            prev_word, prev_pos = word, pos\n",
    "\n",
    "        if pos[-2:] in ('EF'): # and word[0][-1:] in ['요', '다']:\n",
    "            # words가 꼭 명사를 뜻하는 게 아니고 특색있는 키워드 모두를 포함\n",
    "            if len(buff) > 0:\n",
    "                words.append(buff)\n",
    "            buff = ''\n",
    "            # 문장의 끝을 구분\n",
    "            #words.append('(절취선)')\n",
    "            \n",
    "            words = after_effect(words)\n",
    "            ret.append([word, condition, words, nouns, adverbs])\n",
    "            idx += 1\n",
    "            if condition: condidx += 1\n",
    "            nouns = []\n",
    "            words = []\n",
    "            adverbs = []\n",
    "            condition = False\n",
    "    if len(buff) > 0:\n",
    "        words.append(buff)\n",
    "    if len(words) > 0:\n",
    "        words = after_effect(words)\n",
    "        ret.append([word, condition, words, nouns, adverbs])\n",
    "        idx += 1\n",
    "        if condition: condidx += 1\n",
    "    etc.append(condidx / idx)\n",
    "    return ret, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-10 17:52:04.614397 0\n"
     ]
    }
   ],
   "source": [
    "smishings = []\n",
    "normals = []\n",
    "idx = 0\n",
    "for idx, item in df.iterrows():\n",
    "    #print(item.text)\n",
    "    splited, etc = parse_sentence(item.text)\n",
    "    etc.append(np.log(len(item.text))/8)  # 문장 전체의 길이\n",
    "    etc.append(np.log(len(splited))/4)  # 문장의 개수\n",
    "    splited.append(etc)\n",
    "    splited.append(item.id)\n",
    "    #splited = m.parse(item.text).split()\n",
    "    if item.smishing == 1:\n",
    "        smishings.append(splited)\n",
    "    else:\n",
    "        normals.append(splited)\n",
    "    if idx % 100000 == 0:\n",
    "        print(datetime.now(), idx)\n",
    "    idx += 1\n",
    "#     if idx > 20000:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'namals shape : {normals.shape}')\n",
    "print(f'smishings shape : {smishings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d4fd084179d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mIDX_TO_CUT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnorm_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormal\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormals\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mIDX_TO_CUT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPOS_IDX_IN_ARR\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnorm_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mnorm_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-d4fd084179d4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mIDX_TO_CUT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnorm_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormal\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormals\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mIDX_TO_CUT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPOS_IDX_IN_ARR\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnorm_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mnorm_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 스미싱에만 등장하는 noun들 : smish_target_words\n",
    "NORM_THRESHOLD, SMISH_THRESHOLD = 500, 2\n",
    "POS_IDX_IN_ARR = 3\n",
    "IDX_TO_CUT = -2\n",
    "norm_dict = {}\n",
    "for item in [x for normal in normals for row in normal[:IDX_TO_CUT] for x in row[POS_IDX_IN_ARR]]:\n",
    "    if item in norm_dict:\n",
    "        norm_dict[item] += 1\n",
    "    else:\n",
    "        norm_dict[item] = 1\n",
    "norm_filter_words = {x:norm_dict.get(x) for x in norm_dict if norm_dict.get(x) > NORM_THRESHOLD}\n",
    "\n",
    "smish_dict = {}\n",
    "for item in [x for smishing in smishings for row in smishing[:IDX_TO_CUT] for x in row[POS_IDX_IN_ARR]]:\n",
    "    if item in smish_dict:\n",
    "        smish_dict[item] += 1\n",
    "    else:\n",
    "        smish_dict[item] = 1\n",
    "smish_filter_words = {x:smish_dict.get(x) for x in smish_dict if smish_dict.get(x) > SMISH_THRESHOLD}\n",
    "        \n",
    "word_only_in_smishings = [word for word in smish_dict if word not in norm_filter_words]\n",
    "word_only_in_normals = [word for word in norm_dict if word not in smish_filter_words]\n",
    "\n",
    "norm_target_words = {x:norm_dict.get(x) for x in word_only_in_normals if norm_dict.get(x) > NORM_THRESHOLD}\n",
    "smish_target_words = {x:smish_dict.get(x) for x in word_only_in_smishings if smish_dict.get(x) > SMISH_THRESHOLD}\n",
    "print('selected normal-like words count:', len(norm_target_words))\n",
    "print('selected smishing-like words count:', len(smish_target_words))\n",
    "\n",
    "smishing_word_cnt, smishing_noword_cnt = [], []\n",
    "normal_word_cnt, normal_noword_cnt = [], []\n",
    "for smishing in smishings:\n",
    "    notarget_word_list = [x for row in smishing[:IDX_TO_CUT] for x in row[POS_IDX_IN_ARR] if x in norm_target_words]\n",
    "    target_word_list = [x for row in smishing[:IDX_TO_CUT] for x in row[POS_IDX_IN_ARR] if x in smish_target_words]\n",
    "    smishing.insert(-2, notarget_word_list)\n",
    "    smishing.insert(-2, target_word_list)\n",
    "    smishing_noword_cnt.append(len(notarget_word_list))\n",
    "    smishing_word_cnt.append(len(target_word_list))\n",
    "for normal in normals:\n",
    "    notarget_word_list = [x for row in normal[:IDX_TO_CUT] for x in row[POS_IDX_IN_ARR] if x in norm_target_words]\n",
    "    target_word_list = [x for row in normal[:IDX_TO_CUT] for x in row[POS_IDX_IN_ARR] if x in smish_target_words]\n",
    "    normal.insert(-2, notarget_word_list)\n",
    "    normal.insert(-2, target_word_list)\n",
    "    normal_noword_cnt.append(len(notarget_word_list))\n",
    "    normal_word_cnt.append(len(target_word_list))\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(normal_noword_cnt)\n",
    "plt.plot(smishing_noword_cnt)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(smishing_word_cnt)\n",
    "plt.plot(normal_word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
